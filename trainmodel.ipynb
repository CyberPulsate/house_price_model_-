{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Adatok betöltése\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain.csv\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m#csv fájl beolvasása\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Adatok betöltése\n",
    "train_data = pd.read_csv('train.csv') #csv fájl beolvasása"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célváltozó és jellemzők kiválasztása\n",
    "X = train_data.drop(columns=['SalePrice']) #Eltávolítjuk az oszlopot\n",
    "y = train_data['SalePrice'] #Létrehozzuk a célváltozót\n",
    "\n",
    "# Numerikus és kategorikus oszlopok kiválasztása\n",
    "num_cols = X.select_dtypes(include=['int64', 'float64']).columns #Egész és lebegőpontos számok kiválasztása\n",
    "cat_cols = X.select_dtypes(include=['object']).columns #Stringek kiválasztása"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adatfeldolgozás, pipeline\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')), #A hiányzó adatok helyére átlagot számítunk\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),#Pótoljuk a hiányzó értékeket\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer( #összeállítjuk az oszlopokat. \n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_cols),\n",
    "        ('cat', categorical_transformer, cat_cols)\n",
    "    ])\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', RandomForestRegressor(n_estimators=100, random_state=42))#döntési fa összeállítása\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adatok felosztása tanító és tesztelő halmazokra\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X: Ez az input feature mátrix, amely tartalmazza az összes bemeneti változót (független változókat), amelyek alapján a modell tanulni fog.\n",
    "y: Ez a célváltozó vektor, amely tartalmazza a célváltozókat, amiket a modell prediktálni fog.\n",
    "test_size: Ez a paraméter azt határozza meg, hogy milyen arányban legyen felosztva az eredeti adathalmaz a teszt adathalmazba. Például test_size=0.2 azt jelenti, hogy az adatok 20%-a kerül a teszt adathalmazba, és 80%-a a tanító adathalmazba.\n",
    "andom_state: Ez a paraméter meghatározza a véletlenszám-generátor kezdőállapotát, ami befolyásolja az adatok felosztásának véletlenszerűségét. Ha megadunk egy konkrét számot (pl. random_state=42), akkor az adatok minden futtatás során ugyanúgy fognak felosztódni, ami segíti a reprodukálhatóságot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline betanítása\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Modell mentése\n",
    "joblib.dump(pipeline, 'house_price_model.pkl')\n",
    "print(\"Model trained and saved as house_price_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REST API\n",
    "from flask import Flask, request, jsonify\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# Flask alkalmazás létrehozása\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Modell betöltése\n",
    "model = joblib.load('house_price_model.pkl')\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    data = request.get_json(force=True)\n",
    "    data_df = pd.DataFrame([data])\n",
    "    prediction = model.predict(data_df)\n",
    "    return jsonify({'prediction': prediction[0]})\n",
    "\n",
    "if __name__ == '__main__': #Ez a kifejezés biztosítja, hogy az alkalmazás csak akkor induljon el, ha közvetlenül futtatjuk a fájlt\n",
    "    app.run(debug=True) #Ez a parancs indítja el a Flask fejlesztői szerverét. debug=True beállítás segítségével bekapcsoljuk a fejlesztői mód funkciót, ami lehetővé teszi számunkra, hogy lássuk a hibákat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
